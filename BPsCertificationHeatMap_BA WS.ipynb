{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Notebook to build the BPs Certifications HeatMap Dashboard for BA of TD Synnex BPs",
            "execution_count": 1,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nimport numpy as np\nimport os, types",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "from botocore.client import Config\nimport ibm_boto3\ndef __iter__(self): return 0\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\nclient_e3f047ef1c72420b9950dc1b6e073ae0 = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='xxxxxxxx',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\n# Excel files content assignment from certifications and participation groups to 3 pandas dataframes\ncerts = client_e3f047ef1c72420b9950dc1b6e073ae0.get_object(Bucket='bpscertsashboard-donotdelete-pr-4h1rarzfjtezdk',Key='Certifications_Badges by Company.xlsx')['Body']\ndf_allcerts = pd.read_excel(certs.read(), skiprows=2)\n\npgs_CS = client_e3f047ef1c72420b9950dc1b6e073ae0.get_object(Bucket='bpscertsashboard-donotdelete-pr-4h1rarzfjtezdk',Key='IV1b CVR VAD BP Overview CS.xlsx')['Body']\ndf_allpgs_CS = pd.read_excel(pgs_CS.read(), skiprows=16)\n\npgs_TD = client_e3f047ef1c72420b9950dc1b6e073ae0.get_object(Bucket='bpscertsashboard-donotdelete-pr-4h1rarzfjtezdk',Key='IV1b CVR VAD BP Overview TD.xlsx')['Body']\ndf_allpgs_TD = pd.read_excel(pgs_TD.read(), skiprows=16)",
            "execution_count": 5,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "#1. Create certifications dataframe with desired columns specified in the \"Cloumns\" list\n##Cambi\u00f3 sig l\u00ednea 30 jun 2022\nColumns = [\"Country\", \"Company ID\", \"BP Name\", \"Credential Name\", \"Preferred VAD(Software)\", \"Credential Type\", \"Participation Group\"]\ndf_selected_certs = df_allcerts[Columns]\n#Change columns names for better understanding\ndf_selected_certs.rename(columns = {\"Preferred VAD(Software)\":\"VAD\"}, inplace = True)\n#dataframe filtering wehre Country = Mexico, and where Participations Groups are of interest\ndf_Mexico_certs = df_selected_certs[(df_selected_certs[\"Country\"] == \"Mexico\") & (\\\n#                              (df_selected_certs[\"Participation Group\"] == \"Cloud Pak for Data & Extensions\") |\\\n#                              (df_selected_certs[\"Participation Group\"] == \"Data Science & AI\") |\\\n#                              (df_selected_certs[\"Participation Group\"] == \"Information Architecture\") |\\\n                              (df_selected_certs[\"Participation Group\"] == \"Digital Business Automation\") |\\\n                              (df_selected_certs[\"Participation Group\"] == \"Application Management & Integration\")\n                                                                                 )]\n# Merge columns Credential Type and Credential Name\ndf_Mexico_certs[\"Credential Type-Name\"] = df_Mexico_certs[\"Credential Type\"].astype(str) +\"-\"+ df_Mexico_certs[\"Credential Name\"]\n# Drop Credential Type and Credential Name columns\ndf_Mexico_certs.drop([\"Credential Name\", \"Credential Type\"], inplace=True, axis = 1)\n##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n#Change columns names for better understanding\ndf_Mexico_certs.rename(columns = {\"Company ID\":\"CE_ID\"}, inplace = True)\n\n#2. Create participation groups dataframe from TD Synnex with desired columns specified in the \"Cloumns\" list\n##Cambi\u00f3 sig l\u00ednea 30 jun 2022\nColumns = [\"CE_ID\",\"COMPANY_NAME\", \"PRODUCT_GROUP_DESC\", \"Revalidation Readiness: Certifications\", \"Current Participation Group Status\", \\\n           \"Revalidation Readiness: Engagement Solution\", \"VAD_NAME\"]\ndf_pgs_TD = df_allpgs_TD[Columns]\n#Change columns names for better understanding\ndf_pgs_TD.rename(columns = {\"COMPANY_NAME\":\"BP Name\", \"PRODUCT_GROUP_DESC\":\"SW Deal Registration\", \\\n                         \"Revalidation Readiness: Certifications\":\"Required Certifications\",\\\n                         \"Current Participation Group Status\":\"Participation Group\", \\\n                         \"Revalidation Readiness: Engagement Solution\":\"Engagement Solution\",\\\n                         \"VAD_NAME\":\"VAD\"\n                        }, inplace = True)\n#Filtrado del dataframe en donde Country = Mexico y cuando los Participations Groups coinciden con los de inter\u00e9s\ndf_selected_pgs_TD = df_pgs_TD[(df_pgs_TD[\"Participation Group\"] == \"Green\") &(\\\n#                            (df_pgs_TD[\"SW Deal Registration\"] == \"Cloud Pak for Data & Extensions\") |\\\n#                            (df_pgs_TD[\"SW Deal Registration\"] == \"Data Science & AI\") |\\\n#                            (df_pgs_TD[\"SW Deal Registration\"] == \"Information Architecture\") |\\\n                            (df_pgs_TD[\"SW Deal Registration\"] == \"Digital Business Automation\") |\\\n                            (df_pgs_TD[\"SW Deal Registration\"] == \"Application Management & Integration\")\n                                                                                                 )]\n\n#3. Create participation groups dataframe from CS with desired columns specified in the \"Cloumns\" list\n##Cambi\u00f3 sig l\u00ednea 30 jun 2022\nColumns = [\"CE_ID\",\"COMPANY_NAME\", \"PRODUCT_GROUP_DESC\", \"Revalidation Readiness: Certifications\", \"Current Participation Group Status\", \\\n           \"Revalidation Readiness: Engagement Solution\", \"VAD_NAME\"]\ndf_pgs_CS = df_allpgs_CS[Columns]\n#Change columns names for better understanding\ndf_pgs_CS.rename(columns = {\"COMPANY_NAME\":\"BP Name\", \"PRODUCT_GROUP_DESC\":\"SW Deal Registration\", \\\n                         \"Revalidation Readiness: Certifications\":\"Required Certifications\",\\\n                         \"Current Participation Group Status\":\"Participation Group\", \\\n                         \"Revalidation Readiness: Engagement Solution\":\"Engagement Solution\",\\\n                         \"VAD_NAME\":\"VAD\"\n                        }, inplace = True)\n#Filtrado del dataframe en donde Country = Mexico y cuando los Participations Groups coinciden con los de inter\u00e9s\ndf_selected_pgs_CS = df_pgs_CS[(df_pgs_CS[\"Participation Group\"] == \"Green\") &(\\\n#                            (df_pgs_CS[\"SW Deal Registration\"] == \"Cloud Pak for Data & Extensions\") |\\\n#                            (df_pgs_CS[\"SW Deal Registration\"] == \"Data Science & AI\") |\\\n#                            (df_pgs_CS[\"SW Deal Registration\"] == \"Information Architecture\") |\\\n                            (df_pgs_CS[\"SW Deal Registration\"] == \"Digital Business Automation\") |\\\n                            (df_pgs_CS[\"SW Deal Registration\"] == \"Application Management & Integration\")\n                                                                                                 )]",
            "execution_count": 6,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/pandas/core/frame.py:5039: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().rename(\n/tmp/wsuser/ipykernel_216/297075492.py:16: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df_Mexico_certs[\"Credential Type-Name\"] = df_Mexico_certs[\"Credential Type\"].astype(str) +\"-\"+ df_Mexico_certs[\"Credential Name\"]\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return super().drop(\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "# Drop of duplicate rows\ndf_Mexico_certs.drop_duplicates(inplace=True, subset=[\"BP Name\",\"Credential Type-Name\", \"Participation Group\"])\n#1. Use of get_dummies (one-hot encoder) to generate new columns with each category of certification in \"Credential Type-Name\" column\nx = pd.get_dummies(df_Mexico_certs[\"Credential Type-Name\"])\ndf_Mexico_certs_BA = pd.concat([df_Mexico_certs, x], axis=1)\n#Assign \"Credential Type-Name\" to a list Credentials to be used later\nCredentials = set(df_Mexico_certs_BA[\"Credential Type-Name\"].values.tolist())\n# Drop \"Credential Name\" column\ndf_Mexico_certs_BA.drop(\"Credential Type-Name\", inplace=True, axis = 1)\n# Drop \"Participation Group\" column\ndf_Mexico_certs_BA.drop(\"Participation Group\", inplace=True, axis = 1)\n\n# Use of get_dummies (one-hot encoder) to generate new columns with each category of participation group from TD in \"SW Deal Registration\" column\ny = pd.get_dummies(df_selected_pgs_TD[\"SW Deal Registration\"], \"PG\")\ndf_selected_pgs_TD_BA = pd.concat([df_selected_pgs_TD, y], axis=1)\n#No tiene duplicados que eliminar\n# Drop \"SW Deal Registration\" column\ndf_selected_pgs_TD_BA.drop(\"SW Deal Registration\", inplace = True, axis = 1)\ndf_selected_pgs_TD_BA.replace(to_replace={\"Green\":1.0, \"Red\":0.0}, inplace=True)\n\n# Use of get_dummies (one-hot encoder) to generate new columns with each category of participation group from CS in \"SW Deal Registration\" column\nz = pd.get_dummies(df_selected_pgs_CS[\"SW Deal Registration\"], \"PG\")\ndf_selected_pgs_CS_BA = pd.concat([df_selected_pgs_CS, z], axis=1)\n#No tiene duplicados que eliminar\n# Drop \"SW Deal Registration\" column\ndf_selected_pgs_CS_BA.drop(\"SW Deal Registration\", inplace = True, axis = 1)\ndf_selected_pgs_CS_BA.replace(to_replace={\"Green\":1.0, \"Red\":0.0}, inplace=True)",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/pandas/util/_decorators.py:311: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  return func(*args, **kwargs)\n",
                    "name": "stderr"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Concat dataframes\ndf1 = df_Mexico_certs_BA\ndf2 = df_selected_pgs_TD_BA\ndf3 = df_selected_pgs_CS_BA\ndf_outer_TD = pd.concat([df2, df1], ignore_index=True, sort=False)\ndf_outer = pd.concat([df_outer_TD, df3], ignore_index=True, sort=False)\n# Replace NaN values with correct information from corresponding Country\ndf_outer[\"Country\"] = df_outer[\"Country\"].fillna(\"Mexico\")\n# Replace the rest of NaN values with Zeros\ndf_outer = df_outer.fillna(0)",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Sort all columns\ndf_outer.sort_values(by=\"BP Name\", inplace=True)\n# Assign \"BP Names\" to a list BpName to be used later\nBpName = df_outer[\"BP Name\"].values.tolist()\n",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "# Algorythm to reduce all the info (columns) of each BP to one row (as BPs info may be represented in more than one row)\ni=0\nfor BP in BpName:\n    if (i == len(BpName)-1): # Si se cumple esta condici\u00f3n es para operar sobre la \u00faltima ocurrencia o rengl\u00f3n\n        index = (BpName.index(BP))\n\n        # Generate a dataframe only with \"Required Certifications\", \"Participation Group\", and \"Engagement Solution\"\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        rcpges = df_outer.iloc[index:i+1,2:5] # Selects excluding last value\n        # Sum the certifications by column (this is no the total of certifications, just put all of them in one row)\n        total_rcpges = rcpges.sum()\n        # Replace the sum of certifications in the row of the first occurrence of the BP Name\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        df_outer.iloc[index,2:5] = total_rcpges        \n        \n        # Generate a dataframe only with the certifications for a specific BP\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        certificaciones = df_outer.iloc[index:i+1,9:] # Selects excluding last value\n        # Sum the certifications by column (this is no the total of certifications, just put all of them in one row)\n        total_certs = certificaciones.sum()\n        # Replace the sum of certifications in the row of the first occurrence of the BP Name\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        df_outer.iloc[index,9:] = total_certs\n        \n        # Generate a dataframe only with the participation groups\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        participation_groups = df_outer.iloc[index:i+1,6:8] # Selects excluding last value\n        # Sum the certifications by column (this is no the total of pgs, just put all of them in one row)\n        total_pgs = participation_groups.sum()\n        # Replace the sum of pgs in the row of the first occurrence of the BP Name\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        df_outer.iloc[index,6:8] = total_pgs\n        break\n    nextBP = BpName[i+1]\n    if (BP != nextBP):\n        index = (BpName.index(BP))\n        \n        # Generate a dataframe only with \"Required Certifications\", \"Participation Group\", and \"Engagement Solution\"\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        rcpges = df_outer.iloc[index:i+1,2:5] # Selects excluding last value\n        # Sum the certifications by column (this is no the total of certifications, just put all of them in one row)\n        total_rcpges = rcpges.sum()\n        # Replace the sum of certifications in the row of the first occurrence of the BP Name\n        df_outer.iloc[index,1:4] = total_rcpges        \n        \n        # Generate a dataframe only with the certifications for a specific BP\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        certificaciones = df_outer.iloc[index:i+1,9:] # Selects excluding last value\n        # Sum the certifications by column (this is no the total of certifications, just put all of them in one row)\n        total_certs = certificaciones.sum()\n        # Replace the sum of certifications in the row of the first occurrence of the BP Name\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        df_outer.iloc[index,9:] = total_certs\n        \n        # Generate a dataframe only with the participation groups\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        participation_groups = df_outer.iloc[index:i+1,6:8] # Selects excluding last value\n        # Sum the certifications by column (this is no the total of pgs, just put all of them in one row)\n        total_pgs = participation_groups.sum()\n        # Replace the sum of pgs in the row of the first occurrence of the BP Name\n        ##Cambi\u00f3 sig l\u00ednea 30 jun 2022\n        df_outer.iloc[index,6:8] = total_pgs\n        i += 1\n    else:\n        i+= 1\n\n# From df_outer drop columns without the sum of certifications and pgs\ndf_outer.drop_duplicates(inplace=True, subset=[\"BP Name\"])",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {
                "scrolled": true
            },
            "cell_type": "code",
            "source": "# Export dataframe to file\nfrom project_lib import Project\nproject = Project(project_id=\"bdf741a6-8022-43b2-b1bd-bddbd42868f5\", project_access_token=\"xxxxxxxxx\")\nproject.save_data(file_name = \"BP_Certifications_Heatmap_BA.csv\", data = df_outer.to_csv(index=False))",
            "execution_count": 16,
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 16,
                    "data": {
                        "text/plain": "{'file_name': 'BP_Certifications_Heatmap_BA.csv',\n 'message': 'File saved to project storage.',\n 'bucket_name': 'bpscertsashboard-donotdelete-pr-4h1rarzfjtezdk',\n 'asset_id': '33cc04b5-be4e-4506-9b03-6bacefcce5db'}"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.12",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}